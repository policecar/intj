# fmt: off

max_output_tokens: 256

# model_name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# user_tag: "<|user|>"
# assistant_tag: "<|assistant|>"
# control_layers: !range [-1, -8, -1]  # start, end, step

model_name: "mistralai/Mistral-7B-Instruct-v0.1"
user_tag: "[INST]"
assistant_tag: "[/INST]"
control_layers: !range [-5, -18, -1]

# model_name: "meta-llama/Meta-Llama-3-8B-Instruct"
# user_tag: "User: "
# assistant_tag: "AI: "
# control_layers: !range [15, 28, 1]

repetition_penalty: 1.3
prompt_lib: "prompts.yaml"  # "cvec.yaml"
prefix_lib: "data/all_truncated_outputs.json"

# fmt: on
